{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-11T04:31:20.136293Z",
     "start_time": "2024-09-11T04:31:19.410246Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9576369996113486\n",
      "Training Confusion Matrix:\n",
      "[[4343  109]\n",
      " [  84 2464]]\n",
      "Training Precision: 0.967032967032967\n",
      "Training Recall: 0.9623120484280414\n",
      "Training F1 Score: 0.9724285714285714\n",
      "--------------------\n",
      "Testing Accuracy: 0.8981981981981982\n",
      "Testing Confusion Matrix:\n",
      "[[1808  113]\n",
      " [  82  997]]\n",
      "Testing Precision: 0.9240037071362373\n",
      "Testing Recall: 0.910918227501142\n",
      "Testing F1 Score: 0.935\n",
      "--------------------\n",
      "The model is well-fitted, as the difference in performance on the training and test sets is not significant.\n"
     ]
    }
   ],
   "source": [
    "def get_metrics(x_vals, y_vals, knn):\n",
    "    y_pred = knn.predict(x_vals)\n",
    "    conf_matrix = confusion_matrix(y_vals, y_pred)\n",
    "    precision = precision_score(y_vals, y_pred)\n",
    "    recall = recall_score(y_vals, y_pred)\n",
    "    f1 = f1_score(y_vals, y_pred)\n",
    "    accuracy = accuracy_score(y_vals, y_pred)\n",
    "    return precision, conf_matrix, recall, f1, accuracy\n",
    "\n",
    "def evaluate_knn_classifier(X_train, X_test, y_train, y_test, n_neighbors=3):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a K-Nearest Neighbors (KNN) classifier on training and testing data.\n",
    "\n",
    "    Args:\n",
    "        X_train (numpy.ndarray or pandas.DataFrame): The training feature data.\n",
    "        X_test (numpy.ndarray or pandas.DataFrame): The testing feature data.\n",
    "        y_train (numpy.ndarray or pandas.Series): The training target variable.\n",
    "        y_test (numpy.ndarray or pandas.Series): The testing target variable.\n",
    "        n_neighbors (int): The number of neighbors to use in the KNN classifier.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the training and testing performance metrics (accuracy, confusion matrix, precision, recall, F1 score).\n",
    "    \"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    return *get_metrics(X_train, y_train, knn), *get_metrics(X_test, y_test, knn)\n",
    "\n",
    "def split_data(X, y, test_size=0.3):\n",
    "    \"\"\"\n",
    "    Splits data into training and testing sets.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray or pandas.DataFrame): The feature data.\n",
    "        y (numpy.ndarray or pandas.Series): The target variable.\n",
    "        test_size (float): The proportion of the dataset to include in the test split.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the training and testing data (X_train, X_test, y_train, y_test).\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "df = pd.read_csv('../Datasets/final_test.csv', nrows=10000)\n",
    "df.rename(columns={'text': 'text', 'label': 'generated'}, inplace=True)\n",
    "df = df.dropna()\n",
    "    \n",
    "vectorizer = TfidfVectorizer(max_features=500, ngram_range=(1, 2), stop_words='english')\n",
    "vector_data = vectorizer.fit_transform(df['text']).toarray()\n",
    "\n",
    "(train_accuracy, train_conf_matrix, train_precision, train_recall, train_f1,\n",
    " test_accuracy, test_conf_matrix, test_precision, test_recall, test_f1) = evaluate_knn_classifier(*split_data(vector_data, df[\"generated\"]))\n",
    "\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Training Confusion Matrix:\")\n",
    "print(train_conf_matrix)\n",
    "print(\"Training Precision:\", train_precision)\n",
    "print(\"Training Recall:\", train_recall)\n",
    "print(\"Training F1 Score:\", train_f1)\n",
    "\n",
    "print(\"-\" * 20)\n",
    "\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "print(\"Testing Confusion Matrix:\")\n",
    "print(test_conf_matrix)\n",
    "print(\"Testing Precision:\", test_precision)\n",
    "print(\"Testing Recall:\", test_recall)\n",
    "print(\"Testing F1 Score:\", test_f1)\n",
    "\n",
    "print(\"-\" * 20)\n",
    "\n",
    "accuracy_difference = abs(train_accuracy - test_accuracy)\n",
    "\n",
    "if accuracy_difference > 0.07:\n",
    "    if train_accuracy > test_accuracy:\n",
    "        print(\"The model is overfitting, as it performs significantly better on the training set than the test set.\")\n",
    "    else:\n",
    "        print(\"The model is underfitting, as it performs significantly better on the test set than the training set.\")\n",
    "else:\n",
    "    print(\"The model is well-fitted, as the difference in performance on the training and test sets is not significant.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T04:37:32.304193Z",
     "start_time": "2024-09-11T04:37:26.850485Z"
    }
   },
   "id": "1bd26ef2d096b3fa",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of the vector space: (10, 5)\n",
      "Number of vectors: 10\n",
      "Rank of matrix A: 3\n",
      "\n",
      "Price of each item: [ 1. 55. 18.]\n",
      "\n",
      "MSE: 3.392732981174528e-27\n",
      "RMSE: 5.82471714435519e-14\n",
      "MAPE: 2.52211295319421e-14\n",
      "R2: 1.0\n"
     ]
    }
   ],
   "source": [
    "def evaluate_price_prediction(purchase_data_matrix, total_price_vector):\n",
    "    \"\"\"\n",
    "    Calculates the price of each item using pseudo-inverse and evaluates the prediction using MSE, RMSE, MAPE, and R2.\n",
    "\n",
    "    Args:\n",
    "        purchase_data_matrix (numpy.ndarray or pandas.DataFrame): The matrix representing the purchase data (excluding total price).\n",
    "        total_price_vector (numpy.ndarray or pandas.Series): The vector representing the total price for each purchase.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the price of each item and the evaluation metrics (MSE, RMSE, MAPE, R2).\n",
    "    \"\"\"\n",
    "    A_INV = np.linalg.pinv(purchase_data_matrix)\n",
    "    price_of_each_item = (A_INV @ total_price_vector)\n",
    "\n",
    "    y_pred = purchase_data_matrix @ price_of_each_item\n",
    "    MSE = np.square(np.subtract(total_price_vector, y_pred)).mean()\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    MAPE = np.mean(np.abs((total_price_vector - y_pred) / total_price_vector)) * 100\n",
    "    R2 = 1 - (np.square(total_price_vector - y_pred).sum() / np.square(total_price_vector - total_price_vector.mean()).sum())\n",
    "\n",
    "    return price_of_each_item, MSE, RMSE, MAPE, R2\n",
    "\n",
    "\n",
    "purchase_data_df = pd.read_excel('../Datasets/Lab Session Data.xlsx', sheet_name='Purchase data', usecols='A:E')\n",
    "purchase_data = purchase_data_df.iloc[:, 1:4]\n",
    "total_price = purchase_data_df.iloc[:, 4]\n",
    "\n",
    "print(\"Dimensionality of the vector space:\", purchase_data_df.shape)\n",
    "print(\"Number of vectors:\", purchase_data_df.shape[0])\n",
    "print(\"Rank of matrix A:\", np.linalg.matrix_rank(purchase_data))\n",
    "\n",
    "print()\n",
    "price_of_each_item, MSE, RMSE, MAPE, R2 = evaluate_price_prediction(purchase_data, total_price)\n",
    "print(\"Price of each item:\", price_of_each_item)\n",
    "print()\n",
    "\n",
    "print(\"MSE:\", MSE)\n",
    "print(\"RMSE:\", RMSE)\n",
    "print(\"MAPE:\", MAPE)\n",
    "print(\"R2:\", R2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-11T04:42:10.496683Z",
     "start_time": "2024-09-11T04:42:10.458432Z"
    }
   },
   "id": "5912774e662e1d13",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a7e8338ef648f81e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
